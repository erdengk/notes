## 第八、神经网络：表述(Neural Networks: Representation)

### 8.1 非线性假设

无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。

普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。

### 8.2 神经元和大脑

神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。

如果你能把几乎任何传感器接入到大脑中，大脑的学习算法就能找出学习数据的方法，并处理这些数据。从某种意义上来说，如果我们能找出大脑的学习算法，然后在计算机上执行大脑学习算法或与之相似的算法，也许这将是我们向人工智能迈进做出的最好的尝试。人工智能的梦想就是：有一天能制造出真正的智能机器。

### 8.3 模型表示1/前向传播

每一个神经元都可以被认为是一个处理单元/神经核（**processing unit**/**Nucleus**），它含有许多输入/树突（**input**/**Dendrite**），并且有一个输出/轴突（**output**/**Axon**）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。

神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫==激活单元，**activation unit**==）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，==参数又可被成为权重（**weight**）==。

![](http://www.ai-start.com/ml2014/images/fbb4ffb48b64468c384647d45f7b86b5.png)

==X1 是输入单元（**input units**）,====A1 a2 是中间单元==它们负责将数据进行处理，然后呈递到下一层。 最后是输出单元，它负责计算

神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个3层的神经网络，第一层成为==输入层（**Input Layer**）==，最后一层称为==输出层（**Output Layer**）==，中间一层成为==隐藏层（**Hidden Layers**）==。我们为每一层都增加一个==偏差单位（**bias unit**）==：

![](http://www.ai-start.com/ml2014/images/8293711e1d23414d0a03f6878f5a2d91.jpg)



上图中每一个 a 都是由上一层所有的 x 和 每层对应的 x 所决定的

把这样从左到右的算法称为==前向传播算法( **FORWARD PROPAGATION** )==

### 8.4 模型表示2

### 8.5 特征和直观理解1



