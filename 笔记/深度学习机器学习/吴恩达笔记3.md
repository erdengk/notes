## 六、逻辑回归(Logistic Regression)

在分类问题中，你要预测的变量`y`是离散的值，我们将学习一种叫做逻辑回归 (**Logistic Regression**) 的算法，这是目前最流行使用最广泛的一种学习算法。

==逻辑回归算法，这个算法的性质是：它的输出值永远在0到 1 之间。==

逻辑回归算法实际上是一种分类算法，它适用于标签 `y` 取值离散的情况，如：1 0 0 1。

### 6.3 判定边界

下决策边界(**decision boundary**)的概念。这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。

### 6.4 代价函数

如何拟合逻辑回归模型的参数

我要定义用来拟合参数的优化目标或者叫代价函数，这便是监督学习问题中的逻辑回归模型的拟合问题

![](http://www.ai-start.com/ml2014/images/f23eebddd70122ef05baa682f4d6bd0f.png)

除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：**共轭梯度**（**Conjugate Gradient**），**局部优化法**(**Broyden fletcher goldfarb shann,BFGS**)和**有限内存局部优化法**(**LBFGS**) ，**fminunc**是 **matlab**和**octave** 中都带的一个最小值优化函数，使用时我们需要提供代价函数和每个参数的求导。

### 6.5 简化的成本函数和梯度下降

==如何运用梯度下降法，来拟合出逻辑回归的参数==

### 6.7 多类别分类：一对多

如何使用逻辑回归 (**logistic regression**)来解决多类别分类问题，具体来说，我想通过一个叫做"一对多" (**one-vs-all**) 的分类算法。

"一对余"方法

abc 三类，拆成 a（bc）、 （ab）c   、（ac）b  三个二元分类问题

## 七、正则化(Regularization)

### 7.1 过拟合的问题