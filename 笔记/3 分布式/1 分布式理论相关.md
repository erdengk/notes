

## CAP

其中C代表一致性 (Consistency)，A代表可用性 (Availability)，P代表分区容错性 (Partition tolerance)。

![img](https://pdai.tech/_images/arch/arch-cap-1.png)

 

### 如何理解 CAP

- `一致性 (Consistency)`: 一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有读操作都不能读到这个数据。
- `可用性 (Availability)`: 对数据更新具备高可用性，即使出现节点失效，请求也能够及时处理，不会一直等待。
- `分区容错性 (Partition tolerance)`: 能容忍网络分区，在网络断开的情况下，被分隔的节点仍能正常对外提供服务。

理解CAP理论最简单的方式是想象两个副本处于分区两侧，即两个副本之间的网络断开，不能通信。

- 如果允许其中一个副本更新，则会导致数据不一致，即丧失了C性质。
- 如果为了保证一致性，将分区某一侧的副本设置为不可用，那么又丧失了A性质。
- 除非两个副本可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。

一般来说使用网络通信的分布式系统，无法舍弃P性质，那么就只能在一致性和可用性上做一个艰难的选择。



### PACELC理论

A 中是有一定争议的，很长时间才返回，虽然可用，但是业务上可能不能接受。并且，系统大部分时间下，分区都是平稳运行的，并不会出错，在这种情况下，系统设计要均衡的其实是延迟与数据一致性的问题，为了保证数据一致性，写入与读取的延迟就会增高。这就引出了 PACELC 理论。 PAC就是CAP，E是else，L是Latency延迟，C是 Consistency。 

![cap-pacelc](https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/theory/distributed-cap-pacelc-1.PNG)

如果发生了P ，那么只能保 A or C

如果没有发生P， 那么就在 L 和 C之前权衡，如果保证了低延时，数据一致性就会降低（副本数量少），如果保证了较高的数据一致性，就会带来相对较高的延时问题（需要同步的副本多）

PACELC理论更进一步描述了即使在没有Partition的场景下，也存在Latency和Consistency之间的取舍，从而为分布式系统的Consistency模型提供了一个更为完整的理论依据。

### PACELC例子1

![consistency-latency](https://wuchangping.oss-cn-hangzhou.aliyuncs.com/distributed/theory/distributed-cap-pacelc-2.PNG)

在强一致性复制场景下，需要三副本都下盘才能返回OK确认信息给client端，假设Master节点向 Slave 节点复制数据，时延的限制是 20ms，有时候，slave 2 硬盘或网络出现故障，Master 往 Slave 复制数据的时延超过 了20ms，这个时候如果还一直等待 slave 2 返回结果再通知给client就会出现性能和时延抖动，而且这种抖动是经常会发生的长尾效应。

依据PACELC理论，我们可以在 consistency和Latency之间做个取舍，比如 slave 2 节点的时延超过 20ms了，就不等待slave 2 返回，master 和 slave 1 返回结果给client即可（此时同步节点大于总结点数的一半），如果 slave 2 出现 超时的 次数超过 5次那么就认为 这个节点可能出现故障，打个故障标签，进行后续的处理。采用这种方式可以消除写时的长尾抖动，获得更优雅的写时性能曲线。

### PACELC例子2-主从同步

举个日常例子，主从同步。

我们业务代码经常可能存在数据写入后立刻查询的操作，因为线上数据库上读写分离，在业务高峰期，存在主从延迟，解决方案一般有两种：

1. **写操作完后Sleep一段微小时间，让数据库完成主从同步**
2. **写操作后完后，直接通过数据库访问层的中间件指定读操作读主库数据**

可以明显看出，这存在在时延（Latency）和一致性（Consistency）上做了权衡，选择方案一，偏向一致性，选择方案二，偏向于低时延。



以MySQL主从复制为例，提供了三种模式：

异步模式：主库执行完客户端提交的事务，立即将结果返给客户端，不关心从库是否已经接收并处理。由于数据同步的延时，客户端在从库上可能读不到最新数据。这种模式对MySQL是性能最佳的，但是用户需要权衡，业务能否忍受这种延时。
全同步复制：主库执行完客户端提交的事务，所有的从库都执行了该事务才返回结果。这样保证强一致性，但是响应时间变长了。
半同步复制：主库在执行完客户端提交的事务后，等待至少一个从库接收到并写到 relay log 中，才返回给客户端。这样做延迟小了很多，相比于异步复制，数据更加不容易丢失。

### 关联问题：eureka属于AP系统吗？它明明没有放弃一致性啊？

描述AP和CP时，通常都会以eureka和zookeeper来具体。eureka是AP的代表作，zookeeper则是CP的代表作。二者之所以这样归类，是因为：

- eureka各节点互相独立、平等的，各节点都提供查询和注册服务（读、写请求）。当发生网络分区，eureka各节点依旧可以接收和注册服务。并且当丢失过多客户端时，节点会进入自我保护（接收新服务注册、不删除过期服务）。在该种模式下，eureka集群剩下最后一个节点，也可以向外提供服务。尽管向外提供的数据可能是过期的数据。
- zookeeper采用的过半原则，由leader处理写请求。当发生网络分区时，leader由于丢失过半的follower，从而处理不了客户端的请求，需要重新选举新leader，期间服务将不可用。糟糕的是，如果集群中没有过半的节点存活，将选举不出新leader，服务将一直处于不可用状态。

回答eureka没有放弃一致性的问题，还得回顾A、C之间的抉择。这二者需要二选一的情况下，一定是发生了网络分区的情况。eureka集群正常运行时，各节点之间可以正常通讯、保持心跳、复制数据，以此保持数据的一致性。但发生网络分区时，eureka确实选择了可用性，而放弃了一致性。

## FLP不可能定理

FLP 不可能定理是分布式系统领域最重要的定理之一，它给出了一个非常重要的结论：在网络可靠并且存在节点失效的异步模型系统中，不存在一个可以解决一致性问题的确定性算法。

这个定理其实也就是告诉我们不要浪费时间去为异步分布式系统设计在任意场景上都能够实现共识的算法，异步系统完全没有办法保证能在有限时间内达成一致。

论文地址：[Impossibility of Distributed Consensuswith One Faulty Process](https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf)


## BASE

 

BASE 理论是对 CAP 理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）

 

**Basically Available**（基本可用）分布式系统在出现不可预知故障的时候，允许损失部分可用性

**Soft state**（软状态）软状态也称为弱状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。

**Eventually consistent**（最终一致性）最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性

### CAP 与 BASE 关系



BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），更具体地说，是对 CAP 中 AP 方案的一个补充。其基本思路就是：通过业务，牺牲强一致性而获得可用性，并允许数据在一段时间内是不一致的，但是最终达到一致性状态。

![img](https://pdai.tech/_images/arch/arch-cap-2.png)

### CAP 与 ACID 关系

 

ACID 是传统数据库常用的设计理念，追求强一致性模型。BASE 支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。

数据库中多个事务并发会存在哪些问题？

- 脏读：事务T1读取了T2更改的x，但是T2在实际存储数据时可能出错回滚了，这时T1读取的实际是无效的数据，这种情况下就是脏读
- 不可重复读：是说在T1读取x时，由于中间T2更改了x，所以T1前后两次读取的x值不相同，这就是所谓的不可重复读
- 幻读：在T1读取符合某个条件的所有记录时，T2增加了一条符合该条件的记录，这就导致T1执行过程中前后读取的记录可能不一致，即T2之后读取时会多出一条记录。

为了解决这些问题，事务提出四种隔离级别来规避上述问题。而解决的就是ACID中的C（一致性），所以ACID中的C（一致性）可以理解为不出现脏读、幻读、不可重复读的问题。可以把它称为“内部一致性”，解决的是数据库内部的一致性问题。

CP中的C（一致性），相对好理解，我把它理解为“外部一致性”。就分布式系统而言的，针对客户端的请求，无论访问那个节点，都能获得最新的相同的值。

ACID 和 BASE 代表了两种截然相反的设计哲学，在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此 ACID 和 BASE 又会结合使用。

## NWR策略-Quorum协议

NWR是一种在分布式存储系统中用于控制一致性级别的一种策略。这个三个字母分别代表着：

- N：分布式系统中，一个有多少个副本数据
- W：处理一次写请求，需要更新多少个副本数据
- R：处理一次读请求，需要读取多少个副本数据

NWR分别设置不同的值时，将会产生不同的一致性效果。

- W+R>N ，整个系统对于客户端的请求能==保证强一致性==。因为写请求和读请求一定存在一个相交的副本，读取的时候返回该副本的数据即可。
- W+R<=N，整个系统对于客户端的请求则不能保证强一致性。

**例子 1**

当我们需要高可写的环境的时候，我们可以配置W=1，如果N=3，那么R = 3。这个时候只要写任何节点成功就认为成功，但是读的时候必须从所有的节点都读出数据

如果我们要求读的高效率，我们可以配置 W=N，R=1。这个时候任何一个节点读成功就认为成功，但是写的时候必须写所有三个节点成功才认为成功。

W、R的大小，直接影响其对应的处理效率。主要注意，读写请求的效率==取决于最慢的副本处理速度==。

不同的NWR取值代表了不同的倾向

如果设定N=3，W=3，R=1，那么强调的是强一致性，写数据的时候一定要把所有的副本刷新，杜绝中间状态。

如果N=3，R=1，W=1，则代表的是可用性，这种情况下一致性就被牺牲掉了。

将 PACELC 均衡权力交给用户



## 一致性分类

什么是一致性，简单的来说就是评判一个并发系统正确与否的标准。

分布式系统中的一致性从强到弱可以分为四种：

1. [线性一致性 （Linearizability：Strong consistency or Atomic consistency)](https://en.wikipedia.org/wiki/Linearizability)
2. [顺序一致性（Sequential consistency）](https://en.wikipedia.org/wiki/Sequential_consistency)
3. [因果一致性（Causal consistency）](https://en.wikipedia.org/wiki/Causal_consistency)
4. [最终一致性（Eventual consistency）](https://en.wikipedia.org/wiki/Eventual_consistency)

强一致性包括线性一致性和顺序一致性，其他的如因果一致性、最终一致都是弱一致性。

强一致性集群中，对任何一个节点发起请求都会得到相同的回复，但将产生相对高的延迟。而弱一致性具有更低的响应延迟，但可能会回复过期的数据，最终一致性即是经过一段时间后终会到达一致的弱一致性。

http://www.xuyasong.com/?p=1970

### 顺序一致性

如果可以找到一个所有 CPU 执行指令的排序，该排序中每个 CPU 要执行指令的顺序得以保持，且实际的 CPU 执行结果与该指令排序的执行结果一致，则称该次执行达到了**顺序一致性**。

==越是宽松的一致性模型，能容纳的事件排列可能性就越多；反之越严格则越少。==

顺序一致性有两个要求：

- 任何一次读都能读到某个数据的最近一次写的数据。
- 系统的所有进程的顺序一致，而且是合理的。即不需要和全局时钟下的顺序一致，错的话一起错，对的话一起对。

#### 例子1

![Sequential Consistency](https://lotabout.me/2019/QQA-What-is-Sequential-Consistency/Sequential-Consistency.svg)

图中 `W(X, 1)` 代表将 1 写入变量 X；`R(X, 1)` 代表读取变量 X，值为 1；横轴代表时间；矩形的长短代表指令持续的时间长短，所以上图其实表示的是多核 CPU 的一次执行结果。

我们找到了指令的一个排序，排序中各个 CPU 的指令顺序得以保持（如 `C: R(X, 1)` 在 `C: R(X, 2)` 之前），这个排序的执行结果与 CPU 分开执行的结果一致，因此该 CPU 的执行是满足顺序一致性的。

注意到==顺序一致性关心的是 CPU 内部执行指令的顺序，而不关心 CPU 之间的相对顺序。==

#### 例子2

![这里写图片描述](https://img-blog.csdn.net/20180721214208274?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoYW8yMDE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

Write(x, 4)：写入x=4
Read(x, 0)：读出x=0

1）图a是满足顺序一致性，但是不满足强一致性的。

原因在于，从全局时钟的观点来看，P2进程对变量X的读操作在P1进程对变量X的写操作之后，然而读出来的却是旧的数据。

但是这个图却是满足顺序一致性的，因为两个进程P1，P2的一致性并没有冲突。从这两个进程的角度来看，顺序应该是这样的：

Write(y,2) , Read(x,0) , Write(x,4), Read(y,2)，

每个进程内部的读写顺序都是合理的，但是这个顺序与全局时钟下看到的顺序并不一样。

2）图b满足强一致性，因为每个读操作都读到了该变量的最新写的结果，同时两个进程看到的操作顺序与全局时钟的顺序一样，都是

Write(y,2) , Read(x,4) , Write(x,4), Read(y,2)。

3）图c不满足顺序一致性，当然也就不满足强一致性了。

因为从进程P1的角度看，它对变量Y的读操作返回了结果0。

那么就是说，P1进程的对变量Y的读操作在P2进程对变量Y的写操作之前，这意味着它认为的顺序是这样的：

write(x,4) , Read(y,0) , Write(y,2), Read(x,0)，

显然这个顺序又是不能被满足的，因为最后一个对变量x的读操作读出来也是旧的数据。因此这个顺序是有冲突的，不满足顺序一致性。

https://blog.csdn.net/chao2016/article/details/81149674

#### 例子3

一条朋友圈下面有多个人发表评论，`朋友圈`这个分布式系统，有两种客户端：`发朋友圈`的客户端负责写入数据，`读朋友圈`的客户端负责读取数据，当然很多时候同一个客户端既能读也能写。

接下来的问题是：

- 这些看朋友圈的人，是否能看到全局一致的数据？即所有人看到的朋友圈都是同一个顺序排列的？

显然，有很多时候，即便是在看同一个朋友圈下的评论回复，不同的人看到也不尽然都是同一个顺序的，所以以上的答案是否定的。那么就引入了下一个问题：

- 如果不同的人看到的朋友圈（包括评论）顺序各有不同，这些顺序又该遵守怎样的规则才是合理的？

一条朋友圈下面有多个人发表评论，可以认为这是一个`二维`的数据：

- 进程（也就是发表评论的人）是一个维度。
- 时间又是另一个维度，即这些评论出现的先后顺序。

但是在阅读这些评论的读者看来，需要将这一份`二维`的数据，去除掉不同进程这个维度，`压平`到只有本进程时间线这一个单一维度上面来，如图所示：

![wechat-2](https://www.codedump.info/media/imgs/20220710-weekly-22/wechat-2.png)

在上图中，在读进程*P*3的视角看来，两个写进程的事件，需要`压平`到本进程的时间线上进行排列，可以看到这些事件在`压平`之后有多种排列的可能性。

将多个写进程的事件进行排列，放到单进程的时间线上，这是一个排列组合问题，如果所有的写进程事件加起来一共有`n`个，那么这些事件的所有排列组合就是n!。比如事件`a`、`b`、`c`，不同的排列一共有这些：

```java
{(a,b,c),(a,c,b),(b,a,c),(b,c,a),(c,a,b),(c,b,a)}
```

一致性模型就是要回答：在所有的这些可能存在的事件排列组合中，按照要求的一致性严格程度，哪些是可以接受的，哪些不可能出现？

后面的讲述将看到：==越是宽松的一致性模型，能容纳的事件排列可能性就越多；反之越严格则越少。==

举一个违反这个条件的反例，如下图所示：

![program-order](https://www.codedump.info/media/imgs/20220710-weekly-22/program-order.png)

上图中：

- 进程p1视角下：程序的执行顺序是先执行 P_1，再执行 P_2。
- 但是到了P3视角下重排事件之后，P1_2出现在了事件P1_1前面，这是不允许出现的，因为违反了原进程P1程序顺序了。

但是，仅靠条件1还不足以满足顺序一致性，于是还有条件2：

- 条件2：对变量的读写要表现得像FIFO一样先入先出，即`每次读到的都是最近写入的数据`。

![FIFO](https://www.codedump.info/media/imgs/20220710-weekly-22/FIFO.png)

#### 特殊例子



在顺序一致性模型下，第一个排列和第二个排列都被认为是正确的。

![seq-model-2](https://www.codedump.info/media/imgs/20220710-weekly-22/seq-model-2.png)

p1_1 , p2_1 , p3_1  和 p1_1 ， p3_1 ， p2_1 都被认为是对的，因为没有违反两个条件

>- 任何一次读都能读到某个数据的最近一次写的数据。
>- 系统的所有进程的顺序一致，而且是合理的。即不需要和全局时钟下的顺序一致，错的话一起错，对的话一起对。

第三个排列违反了条件2

顺序一致性在满足了条件1、2之后，对`不同进程的事件`之间的顺序没有硬性的要求，即便在感官直觉上某事件应该发生得更早，但是只要没有违反这两个条件就可以认为是满足顺序一致性模型的。

于是就出现了更严格的线性一致性，它基于顺序一致性的条件，对事件的先后顺序做了更严格的要求。

https://www.codedump.info/post/20220710-weekly-22

#### 顺序一致性难吗？

难，现代的多核 CPU 依然达不到顺序一致性。

我们知道 CPU 执行的主要瓶颈其实是在与内存交互，工程师为了让 CPU 能高速执行，在 CPU 内部使用了多级缓存。它的存在，使得即使 CPU 内部顺序执行指令，指令的结果也可能不满足顺序一致性：

![CPU Cache and Sequential Consistency](https://lotabout.me/2019/QQA-What-is-Sequential-Consistency/CPU-Cache.svg)

上图中 `(n)` 代表数据的读写步骤。如果 CPU 如上图执行，则得到的结果不满足顺序一致性。

另外 CPU 执行时会乱序执行指令。例如在一些情况下 CPU 会将数据写入的指令提前执行，因为写入内存是很耗时的。同样的，编译器在编译代码时也会重排代码中的指令的顺序，以提升整体的性能。

难以想象，没有了顺序一致性的保证，程序居然还能正确执行。其实，现代硬件体系遵循的其实是:

> sequential consistency for data race free programs

即如果程序没有数据竞争，则 CPU 可以保证顺序一致性，而如果遇到数据竞争，就需要程序里手工使用一些数据同步的机制（如锁）。

工程领域总是伴随着各种权衡(trade-off)，显然保证顺序一致性对 CPU 的性能优化有太多的阻碍，而 CPU 的高性能又是我们所追求的，两害相权取其轻。

https://lotabout.me/2019/QQA-What-is-Sequential-Consistency/



### 线性一致性-背景知识

分布式系统可以抽象成几个部分:

- Client
- Server
- Events
  - Invocation
  - Response
- Operations
  - Read
  - Write

一个分布式系统通常有两种角色，Client 和 Server。Client 通过发起请求来获取 Server 的服务。一次完整请求由两个事件组成，Invocation（以下简称 Inv）和 Response（以下简称 Resp）。一个请求中包含一个 Operation，有两种类型 Read 和 Write，最终会在 Server 上执行。

说了一堆不明所以的概念，现在来看如何用这些表示分布式系统的行为。

![图例 1](https://img1.www.pingcap.com/prod/1_779a02dad8.png)

上图展示了 Client A 的一个请求从发起到结束的过程。变量 x 的初始值是 1，“x R() A” 是一个事件 Inv 意思是 A 发起了读请求，相应的 “x OK(1) A” 就是事件 Resp，意思是 A 读到了 x 且值为 1，Server 执行读操作（Operation）。

### 线性一致性

最强的一致性要求

它基于顺序一致性的条件，对事件的先后顺序做了更严格的要求。

怎样才能达到线性一致？这就要求 Server 在执行 Operations 时需要满足以下三点：

1. 瞬间完成（或者原子性）
2. 发生在 Inv 和 Resp 两个事件之间
3. 反映出“最新”的值

举一个例子，用以解释上面三点。

>另一种说法
>
>- 不能打乱单进程的程序顺序，同一个进程里的事件先后顺序要得到保留。
>- 不同进程的事件，如果在时间上不重叠，即不是并发事件，那么要求这个先后顺序在重排之后保持一致。
>- 每次读出来的都是最新的值，而且一旦形成了一个排列，要求系统中所有进程都是同样的一个排列。

#### 例子1

![图例 2](https://img1.www.pingcap.com/prod/2_a7d6409a25.png)

先下结论，上图表示的行为满足线性一致。

对于同一个对象 x，其初始值为 1，客户端 ABCD 并发地进行了请求，按照真实时间（real-time）顺序，各个事件的发生顺序如上图所示。

对于任意一次请求都需要一段时间才能完成，例如 A，“x R() A” 到 “x Ok(1) A” 之间的那条线段就代表那次请求花费的时间，而请求中的读操作在 Server 上的执行时间是很短的，相对于整个请求可以认为瞬间，读操作表示为点，并且在该线段上。

线性一致性中没有规定读操作发生的时刻，也就说该点可以在线段上的任意位置，可以在中点，也可以在最后，当然在最开始也无妨。

下面说第三点。

反映出“最新”的值？我觉得三点中最难理解就是它了。

先不急于对“最新”下定义，来看看上图中 x 所有可能的值，显然只有 1 和 2。

四个次请求中只有 B 进行了写请求，改变了 x 的值，我们从 B 着手分析，明确 x 在各个时刻的值。

由于不能确定 B 的 W（写操作）在哪个时刻发生，能确定的只有一个区间，因此可以引入**上下限**的概念。

对于 x=1，它的上下限为**开始到事件“x W(2) B”**，在这个范围内所有的读操作必定读到 1。对于 x=2，它的上下限为 **事件“x Ok() B”** 到结束，在这个范围内所有的读操作必定读到 2。

那么“x W(2) B”到“x Ok() B”这段范围，x 的值是什么？**1 或者 2**。由此可以将 x 分为三个阶段，各阶段"最新"的值如下图所示：

![图例 3](https://img1.www.pingcap.com/prod/3_19ff54b5b4.png)

清楚了 x 的变化后理解例子中 A C D 的读到结果就很容易了。

最后返回的 D 读到了 1，看起来是 “stale read”，其实并不是，它仍满足线性一致性。

==D 请求横跨了三个阶段，而读可能发生在任意时刻，所以 1 或 2 都行。==同理，A 读到的值也可以是 2。C 就不太一样了，C 只有读到了 2 才能满足线性一致。

因为 “x R() C” 发生在 “x Ok() B” 之后（happen before ），可以推出 R 发生在 W 之后，那么 R 一定得读到 W 完成之后的结果：2。

**一句话概括：在分布式系统上实现寄存器语义。**

>一旦我们将一个变量设置为某个值，例如 a，读取时就会返回 a，直到我们再次对值做了变更。读取一个变量返回最近写入的值。我们称这种系统为有单一值的变量 —— 一个寄存器。

https://blog.csdn.net/u013200380/article/details/113050620

https://tech.meituan.com/2022/08/25/replication-in-meituan-02.html

#### 例子2

如果是线性一致性

下图里只有 `p1_1 , p2_1, p3_1 `是满足线性一致性的排列了

![seq-model-2](https://www.codedump.info/media/imgs/20220710-weekly-22/seq-model-2.png)

![image-20221012163923123](https://raw.githubusercontent.com/erdengk/picGo/main/img/202210121639281.png)



这还是最开始解释顺序一致性模型的图，但是在线性一致性的条件下，找不到能够满足条件的排列了。

这是因为：

- 事件 P2_1 和 P1_2 都在事件 P1_1 之后，这个顺序需要得到保持。
- 而事件 P3_1 在事件 P2_1 和 P1_2 之后，这个顺序也需要得到保持。
- 如果保持了前面两个顺序，那么 P3_1 执行的时候，必然读不出来A，而应该是B或者C（即 P2_1 或者 P1_2的执行结果）。

#### 顺序一致性和线性一致性总结

可以看到，如果满足线性一致性，就一定满足顺序一致性，因为后者的条件是前者的真子集。

除了满足这些条件以外，这两个一致性还有一个要求：==系统中所有进程的顺序是一致的，即如果系统中的进程A按照要求使用了某一种排序，即便有其他排序的可能性存在，系统中的其他进程也必须使用这种排序，系统中只能用一种满足要求的排序。==

这个要求，使得满足顺序和线性一致性的系统，对外看起来“表现得像只有一个副本”一样。

但因果一致性则与此不同：只要满足因果一致性的条件，即便不同进程的事件排列不一致也没有关系。

#### 关联问题：线性一致性和序列化（Linearizability and Serializability）

Serializability: 数据库领域的ACID中的I。 数据库的四种隔离级别，由弱到强分别是Read Uncommitted,Read Committed(RC),Repeatable Read(RR)和Serializable。

Serializable的含义是：对并发事务包含的操作进行调度后的结果和某种把这些事务一个接一个的执行之后的结果一样。最简单的一种调度实现就是真的把所有的事务进行排队，一个个的执行，显然这满足Serializability，问题就是性能。可以看出Serializability是与数据库事务相关的一个概念，一个事务包含多个读，写操作，这些操作由涉及到多个数据对象。

- Linearizability: 针对单个操作，单个数据对象而说的。属于CAP中C这个范畴。一个数据被更新后，能够立马被后续的读操作读到。
- Strict Serializability: 同时满足Serializability和Linearizability。

==例子：==

两个事务T1,T2，T1先开始，更新数据对象o，T1提交。接着T2开始，读数据对象o，提交。以下两种调度：

1. T1,T2，满足Serializability，也满足Linearizability。
2. T2,T1，满足Serializability，不满足Linearizability，因为T1之前更新的数据T2读不到。

### 因果一致性

因果一致性，属于弱一致性，因为在Causal consistency中，==只对有因果关系的事件有顺序要求==。

没有因果一致性时会发生如下情形：

- 夏侯铁柱在朋友圈发表状态“我戒指丢了”
- 夏侯铁柱在同一条状态下评论“我找到啦”
- 诸葛建国在同一条状态下评论“太棒了”
- 远在美国的键盘侠看到“我戒指丢了”“太棒了”，开始喷诸葛建国
- 远在美国的键盘侠看到“我戒指丢了”“我找到啦”“太棒了”，意识到喷错人了

所以很多系统采用因果一致性系统来避免这种问题，例如微信的朋友圈就采用了因果一致性，可以参考：https://www.useit.com.cn/thread-10587-1-1.html

![img](http://vermouth-blog-image.oss-accelerate.aliyuncs.com/monitor/0fdd02d5-1d9b-44ac-941f-5a61d06f5eb5.jpg?x-oss-process=style/watermark)

#### 例子

以`评论朋友圈`这个行为来解释因果一致性再合适不过：

- 评论另一个用户的评论：相当于进程给另一个进程发消息，肯定要求满足`happen-before`关系，即先有了评论，才能针对这个评论发表评论。
- 同一个用户的评论：相当于同一个进程的事件，也是必须满足`happen-before`关系才行。

以下图为例：

![casual-model](https://www.codedump.info/media/imgs/20220710-weekly-22/casual-model.png)

一共有4个朋友圈的读者，它们看到的评论顺序都各不一样：

- 最上面的两个读者，读到的顺序都满足因果一致性，因此即便是不一样的顺序也是正确的。
- 最下面的两个读者，顺序都不满足因果一致性：
  - A回复B这个事件出现在了B回复A之前，不符合多进程之间的`happen-before`关系。
  - A回复C这个事件在进程A中应该在A回复B之前，不符合同一进程的事件之间的先后顺序。

### 最终一致性

最终一致性这个词大家听到的次数应该是最多的，也是弱一致性，不过因为大多数场景下用户可以接受，应用也就比较广泛。

理念：不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。

简单说，就是在一段时间后，节点间的数据会最终达到一致状态。

redis主备、mongoDB、乃至mysql热备都可以算是最终一致性，甚至如果我记录操作日志，然后在副本故障了100天之后手动在副本上执行日志以达成一致，也算是符合最终一致性的定义。有人说最终一致性就是没有一致性，因为没人可以知道什么时候算是最终。

最终一致其实分支很多，以下都是他的变种：

- Causal consistency（因果一致性）
- Read-your-writes consistency （读己所写一致性）
- Session consistency （会话一致性）
- Monotonic read consistency （单调读一致性）
- Monotonic write consistency （单调写一致性）

BASE理论中的 E，就是Eventual consistency最终一致

## 总结

- 在分布式系统中，多个进程组合在一起协调工作，产生多个事件，事件之间可以有多种排列的可能性。

- 一致性模型本质上要回答这个问题：按照该一致性模型定义，怎样的事件发生顺序的排列才符合要求？

- 顺序一致性和线性一致性都意图让系统中所有进程`看起来`有统一的全局事件顺序，但是两者的要求不同，顺序一致性：

  - 条件1：每个进程的执行顺序要和该进程的程序执行顺序保持一致。
  - 条件2：对变量的读写要表现得像FIFO一样先入先出，即每次读到的都是最近写入的数据。

  只要满足这两个条件，顺序一致性对事件之间的先后顺序并没有硬性要求，而线性一致性在此基础上多了条件3：

  - 条件3：不同进程的事件，如果在时间上不重叠，即不是并发事件，那么要求这个先后顺序在重排之后保持一致。

- 因果一致性是更弱的一致性，只要满足`happen-before`关系即可。由于`happen-before`关系实际上是由Lamport时钟定义的，这是一种逻辑时钟，所以不同的读者看到的先后顺序可能会有点`反直觉`，但是只要满足`happen-before`关系就是正确的。

大佬的总结链接：https://www.codedump.info/post/20220710-weekly-22/#%E6%80%BB%E7%BB%93



## ACID/2PC/3PC/TCC/Paxos 关系

ACID 是处理事务的原则，限定了原子性、一致性、隔离性、持久性。ACID、CAP、BASE这些都只是理论，只是在实现时的目标或者折中，ACID 专注于分布式事务，CAP 和 BASE是分布式通用理论。

解决分布式事务时有 2pc、3pc、tcc 等方式，通过增加协调者来进行协商，里面也有最终一致的思想。

而Paxos协议与分布式事务并不是同一层面的东西，Paxos用于解决多个副本之间的一致性问题。比如日志同步，保证各个节点的日志一致性，选主的唯一性。简而言之，2PC用于保证多个数据分片上事务的原子性，Paxos协议用于保证同一个数据分片在多个副本的一致性，所以两者可以是互补的关系，不是替代关系。对于2PC协调者单点问题，可以利用Paxos协议解决，当协调者出问题时，选一个新的协调者继续提供服务。原理上Paxos和 2PC相似，但目的上是不同的。etcd 中也有事务的操作，比如迷你事务

## 微服务基础-康威定律

微服务这个概念很早就提出了， 真正火起来是在2016年左右，而康威定律(Conway's Law)就是微服务理论基础。

第一定律

组织沟通方式会通过系统设计表达出来

就是说架构的布局和组织结构会有相似。

第二定律

时间再多一件事情也不可能做得完美，但总有时间做完一件事情

一口气吃不成胖子，先搞定能搞定的。

第三定律

线型系统和线型组织架构间潜在的异质同态特性

种瓜得瓜，做独立自治的子系统减少沟通成本。

第四定律

大的系统组织总是比小系统更倾向于分解

合久必分，分而治之。





## Refernce

http://zhangtielei.com/posts/blog-distributed-strong-weak-consistency.html

https://cn.pingcap.com/blog/linearizability-and-raft

http://www.choudan.net/2013/08/07/CAP%E7%90%86%E8%AE%BA%E5%92%8CNWR%E7%AD%96%E7%95%A5.html

https://blog.csdn.net/m0_68850571/article/details/126140636

https://www.changping.me/2020/04/10/distributed-theory-cap-pacelc/

https://pdai.tech/md/dev-spec/spec/dev-microservice-kangwei.html

https://www.52code.net/a/8xjTPFSabM

https://pdai.tech/md/arch/arch-z-theory.html

https://cloud.tencent.com/developer/article/1752382

