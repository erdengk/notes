## Kafka 基础

###   Kafka 是什么？主要应用场景有哪些？  

Kafka 是一个分布式流式处理平台。

流平台具有三个关键功能：

⚫ 消息队列：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息

队列的原因。

⚫ 容错的持久方式存储记录消息流： Kafka 会把消息持久化到磁盘，有效避免了消息丢失的

风险。

⚫ 流式处理平台： 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。

Kafka 主要有两大应用场景：

⚫ 消息队列 ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。

⚫ 数据处理： 构建实时的流数据处理程序来转换或处理数据流。

### Kafka中有哪几个组件?

- 主题topic：Kafka主题是一堆或一组消息。
- 生产者producer：在Kafka，生产者发布通信以及向Kafka主题发布消息。
- 消费者consumer：Kafka消费者订阅了一个主题，并且还从主题中读取和处理消息。
- 经纪人broker：在管理主题中的消息存储时，我们使用Kafka Brokers。



### 什么是 Producer、Consumer、Broker、Topic、Partition？

Kafka 将生产者发布的消息发送到 Topic（主题） 中，需要这些消息的消费者可以订阅这些 Topic（主题）。Kafka 比较重要的几个概念：

⚫ Producer（生产者） : 产生消息的一方。

⚫ Consumer（消费者） : 消费消息的一方。

⚫ Broker（代理） : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个Kafka Cluster。 

⚫ Topic（主题） : Producer 将消息发送到特定的主题Consumer 通过订阅特定的Topic(主题) 来消费消息。

⚫ Partition（分区） : Partition 属于 Topic 的一部分。一个 Topic 可以有多个Partition ，并且同一 Topic 下的Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。

### 什么是消费者组

消费者组是Kafka独有的概念，即消费者组是Kafkaᨀ供的可扩展且具有容错性的消费者机制。

但实际上，消费者组（Consumer Group）其实包含两个概念，作为队列，消费者组允许你分割数据处理到一组进程集合上（即一个消费者组中可以包含多个消费者进程，他们共同消费该topic的数据），这有助于你的消费能力的动态调整；作为发布-订阅模型（publish-subscribe），Kafka允许你将同一份消息广播到多个消费者组里，以此来丰富多种数据使用场景。

需要注意的是：在消费者组中，多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有相同的组ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。 因此，消费者组在一定程度上也保证了消费者程序的高可用性。

### ISR在Kafka环境中代表什么？

ISR指的是同步副本。这些通常被分类为一组消息副本，它们被同步为领导者。

###   Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么  

![img](https://picx.zhimg.com/80/v2-f43ebff6ffe1ad5aaabff7e69e84e197_720w.webp?source=1940ef5c)

ISR : In-Sync Replicas 副本同步队列
AR : Assigned Replicas 所有副本

ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。

Leader 负责维护和跟踪 ISR 集合中所有 Follower 副本的滞后状态，当 Follower 副本落后过多时，就会将其放入 OSR 集合，当 Follower 副本追上了 Leader 的进度时，就会将其放入 ISR 集合。

默认情况下，只有 **ISR 中的副本才有资格晋升为 Leader**。



### kafka中 位移（offset）的作用

在Kafka中，每个主题分区下的每条消息都被赋予了一个唯一的ID数值，用于标识它在分区中的位置。这个ID数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。

### **Kafka** **中的**HW、LEO、LSO、LW分别代表什么？

HW：高水位，指消费者只能拉取到这个offset之前的数据

严格来说，它表示的就是位置信息，即位移（offset）。取 partition 对应的 ISR 中 最小的 LEO 作为 HW，consumer 最多只能消费到 HW 所在的位置上一条信息。

LEO：标识当前日志文件中下一条待写入的消息的offset，大小等于当前日志文件最后一条消息的offset+1.

![img](https://img-blog.csdnimg.cn/8a6f34ba98544ae3985adf10fedd2a1b.png)

LSO：是 LastStableOffset 的简称，对未完成的事务而言，LSO 的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同 HW 相同

LW：Low Watermark 低水位, 代表 AR 集合中最小的 logStartOffset 值。

### 为什么Kafka技术很重要？

- 高吞吐量：我们在Kafka中不需要任何大型硬件，因为它能够处理高速和大容量数据。此外，它还可以支持每秒数千条消息的消息吞吐量。

- 低延迟：Kafka可以轻松处理这些消息，具有毫秒级的极低延迟，这是大多数新用例所要求的。

- 容错：Kafka能够抵抗集群中的节点/机器故障。

- 耐久性：由于Kafka支持消息复制，因此消息永远不会丢失。这是耐久性背后的原因之一。

- 可扩展性：卡夫卡可以扩展，而不需要通过添加额外的节点而在运行中造成任何停机

  

## Kafka设计

### Kafka为什么那么快

1.**顺序读写**磁盘分为顺序读写与[随机读写](https://www.zhihu.com/search?q=随机读写&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2535501775})，基于磁盘的随机读写确实很慢，但磁盘的顺序读写性能却很高，kafka 这里采用的就是顺序读写。  

2.**Page Cache**为了优化读写性能，Kafka 利用了**操作系统本身的 Page Cache**，就是利用操作系统自身的内存而不是JVM[空间内存](https://www.zhihu.com/search?q=空间内存&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2535501775})。  

3.**零拷贝**Kafka使用了零拷贝技术，也就是**直接将数据从内核空间的读缓冲区直接拷贝到内核空间的 socket 缓冲区**，然后再写入到 NIC 缓冲区，避免了在内核空间和用户空间之间穿梭。  

4.**分区分段+索引**Kafka 的 message 是按 topic分 类存储的，topic 中的数据又是按照一个一个的 partition 即分区存储到不同 broker 节点。每个 partition 对应了操作系统上的一个文件夹，partition 实际上又是按照segment分段存储的。通过这种分区分段的设计，Kafka 的 message 消息实际上是分布式存储在一个一个小的 segment 中的，每次文件操作也是直接操作的 segment。为了进一步的查询优化，Kafka 又默认为分段后的数据文件建立了索引文件，就是文件系统上的index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。  

5.**批量读写Kafka 数据读写也是批量的而不是单条的**,这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。  

6.**批量压缩**Kafka 把所有的消息都变成一个**批量的文件**，并且进行合理的**批量压缩**，减少网络 IO 损耗，通过 mmap 提高 I/O 速度，写入数据的时候由于单个Partion是末尾添加所以速度最优；读取数据的时候配合 sendfile 进行直接读取。



### 零拷贝技术（zero copy）

零拷贝（英语：Zero-copy；也译零复制）技术是指计算机执行操作时，CPU不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省CPU周期和内存带宽。

### kafka在哪些地方使用了零拷贝技术（zero copy）

在Kafka中，体现Zero Copy使用场景的地方有两处：基于mmap的索引和日志文件读写所用的TransportLayer。

先说第一个。索引都是基于MappedByteBuffer的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap虽然避免了不必要的拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap的创建和销毁成本可能是不一样的。很高的创建和销毁开销会抵消Zero Copy带来的性能优势。由于这种不确定性，在Kafka中，只有索引应用了mmap，最核心的日志并未使用mmap机制。

再说第二个。TransportLayer是Kafka传输层的接口。它的某个实现类使用了FileChannel的transferTo方法。该方法底层使用sendfile实现了Zero Copy。对Kafka而言，如果I/O通道使用普通的PLAINTEXT，那么，Kafka就可以利用Zero Copy特性，直接将页缓存中的数据发送到网卡的Buffer中，避免中间的多次拷贝。相反，如果I/O通道启用了SSL，那么，Kafka便无法利用Zero Copy特性了。

如果有10个消费者，**传统方式下，数据复制次数为4\*10=40次，而使用“零拷贝技术”只需要1+10=11次**，一次为从磁盘复制到页面缓存，10次表示10个消费者各自读取一次页面缓存。

https://juejin.cn/post/6863264864140935175

### kafka顺序写



###   kafka producer 收数据，ack  为 0， 1， all 的时候代表啥， 设置 -1 的时候，什么情况下，leader 会认为一条消息 commit了  

1（默认）  数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。

0 生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。

-1 producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。当ISR中所有Replica都向Leader发送ACK时，leader才commit，这时候producer才能认为一个请求中的消息都commit了。



### 讲讲kafka的ack三种机制

request.required.acks 有三个值 0 1 -1(all)，具体如下：

0：生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候就会丢数据。

1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader挂掉后他不确保是否复制完成新 leader 也会导致数据丢失。

-1(all)：服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出的ack，这样数据不会丢失。

### kafka高效文件存储设计特点

- Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。
- 通过索引信息可以快速定位message
- producer生产数据，要写入到log文件中，写的过程中一直追加到文件末尾，为顺序写，官网数据表明。同样的磁盘，顺序写能到600M/S，而随机写只有100K/S



### Kafka 如何保证消息不丢失？

![image-20221006160932750](https://raw.githubusercontent.com/erdengk/picGo/main/img/202210061609862.png)

首先需要弄明白消息为什么会丢失，对于一个消息队列，会有 生产者 、 MQ 、 消费者 这三个角色，在这三个角色数据处理和传输过程中，都有可能会出现消息丢失。

消息丢失的原因以及解决办法：

消费者可能导致数据丢失的情况是：消费者获取到了这条消息后，还未处理， Kafka 就自动提交了offset ，这时 Kafka 就认为消费者已经处理完这条消息，其实消费者才刚准备处理这条消息，这时如果消费者宕机，那这条消息就丢失了。

消费者引起消息丢失的主要原因就是消息还未处理完 Kafka 会自动提交了 offset ，那么只要关闭自动提交 offset ，消费者在处理完之后手动提交 offset ，就可以保证消息不会丢失。

但是此时需要注意重复消费问题，比如消费者刚处理完，还没题交 offset ，这时自己宕机了，此时这条消息肯定会被重复消费一次，==这就需要消费者根据实际情况保证幂等性。==

生产者数据阐述导致的消息丢失：

对于生产者数据传输导致的数据丢失主常见情况是生产者发送消息给 Kafka ，由于网络等原因导致消息丢失，对于这种情况也是通过在 producer 端设置 acks=all 来处理，这个参数是要求 leader 接收到消息后，需要等到所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试。

Kafka 导致的消息丢失

Kafka 导致的数据丢失一个常见的场景就是 Kafka 某个 broker 宕机，，而这个节点正好是某个partition 的 leader 节点，这时需要重新重新选举该 partition 的 leader 。如果该 partition 的 leader 在宕机时刚好还有些数据没有同步到 follower ，此时 leader 挂了，在选举某个follower 成 leader 之后，就会丢失一部分数据。

对于这个问题， Kafka 可以设置如下 4 个参数，来尽量避免消息丢失：

 给 topic 设置 replication.factor 参数：这个值必须大于 1 ，要求每个 partition 必须有至少 2 个副本；

在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1 ，这个参数的含义是一个leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader挂了还有一个 follower 节点。

在 producer 端设置 acks=all ，这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了；

在 producer 端设置 retries=MAX （很大很大很大的一个值，无限次重试的意思）：这个参数的含义是一旦写入失败，就无限重试，卡在这里了。



### kafka 如何保证消息的顺序性

在某些业务场景下，我们需要保证对于有逻辑关联的多条MQ消息被按顺序处理，比如对于某一条数据，正常处理顺序是 新增-更新-删除 ，最终结果是数据被删除；如果消息没有按序消费，处理顺序可能是 删除-新增-更新 ，最终数据没有被删掉，可能会产生一些逻辑错误。对于如何保证消息的顺序性，主要需要考虑如下两点：

==如何保证消息在 Kafka 中顺序性；==

==如何保证消费者处理消费的顺序性。==

如何保证消息在kafka中的顺序性

对于 Kafka ，如果我们创建了一个 topic ，默认有三个 partition 。生产者在写数据的时候，可以指定一个 key ，比如在订单 topic 中我们可以指定订单 id 作为 key ，那么相同订单 id 的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。消费者从partition 中取出来数据的时候，也一定是有顺序的。通过制定 key 的方式首先可以保证在 kafka内部消息是有序的。

如何保证消费者处理消费的顺序性：

对于某个 topic 的一个 partition ，只能被同组内部的一个 consumer 消费，如果这个 consumer内部还是单线程处理，那么其实只要保证消息在 MQ 内部是有顺序的就可以保证消费也是有顺序的。但是单线程吞吐量太低，在处理大量 MQ 消息时，我们一般会开启多线程消费机制，那么如何保证消息在多个线程之间是被顺序处理的呢？

对于多线程消费我们可以预先设置 N 个内存 Queue ，具有相同 key的数据都放到同一个内存 Queue 中；然后开启 N 个线程，每个线程分别消费一个内存 Queue 的数据即可，这样就能保证顺序性。当然，消息放到内存 Queue 中，有可能还未被处理， consumer 发生宕机，内存 Queue 中的数据会全部丢失，这就转变为上面提到如何保证消息不丢失的问题了





### kafka的消费者是pull(拉)还是push(推)模式，这种模式有什么好处？

Kafka 遵循了一种大部分消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从broker 拉取消息。

优点：pull模式消费者自主决定是否批量从broker拉取数据，而push模式在无法知道消费者消费能力情况下，不易控制推送速度，太快可能造成消费者奔溃，太慢又可能造成浪费。

缺点：如果 broker 没有可供消费的消息，将导致 consumer 不断在循环中轮询，直到新消息到到达。为了避免这点，Kafka 有个参数可以让 consumer阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发送)。

### kafka维护消息状态的跟踪方法

Kafka中的Topic 被分成了若干分区，每个分区在同一时间只被一个 consumer 消费。然后再通过offset进行消息位置标记，通过位置偏移来跟踪消费状态。相比其他一些消息队列使用“一个消息被分发到consumer 后 broker 就马上进行标记或者等待 customer 的通知后进行标记”的优点是，避免了通信消息发送后，可能出现的程序奔溃而出现消息丢失或者重复消费的情况。同时也无需维护消息的状态，不用加锁，提高了吞吐量。



### **发送消息的分区策略有哪些？**

1.轮询：**依次**将消息发送该topic下的所有分区，如果在创建消息的时候 key 为 null，Kafka 默认采用这种策略。  

2.key 指定分区：在创建消息是 key 不为空，并且使用默认分区器，Kafka 会将 key 进行 hash，然后**根据hash值映射到指定的分区上**。这样的好处是 key 相同的消息会在一个分区下，Kafka 并不能保证全局有序，但是在每个分区下的消息是有序的，按照顺序存储，按照顺序消费。在保证同一个 key 的消息是有序的，这样基本能满足消息的顺序性的需求。但是**如果 partation 数量发生变化，那就很难保证 key 与分区之间的映射关系了**。  

3.自定义策略：实现 Partitioner 接口就能自定义分区策略。  

4.指定 Partiton 发送



### Kafka 幂等性是如何实现的？

https://www.jianshu.com/p/b1599f46229b



## 容错机制

### Kafka 判断一个节点是否还活着有那两个条件？

节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接；

如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久。

### Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？

​	Kafka 通过给特定 Topic 指定多个 Partition, 而各个Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。

⚫ Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。

###  Kafka 如何保证高可用？

Kafka 的基本架构组成是：由多个 broker 组成一个集群，每个 broker 是一个节点；当创建一个topic 时，这个 topic 会被划分为多个 partition ，每个 partition 可以存在于不同的 broker上，每个 partition 只存放一部分数据。

一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。

在 Kafka 0.8 以后，提供了 HA 机制，就是 replica 副本机制。每个 partition 上的数据都会同步到其它机器，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，消息的生产者和消费者都跟这个 leader 打交道，其他 replica 作为 follower 。写的时候， leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。 Kafka 负责均匀的将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高高容错性。

拥有了 replica 副本机制，如果某个 broker 宕机了，这个 broker 上的 partition 在其他机器上还存在副本。如果这个宕机的 broker 上面有某个 partition 的 leader ，那么此时会从其follower 中重新选举一个新的 leader 出来，这个新的 leader 会继续提供读写服务，这就有达到了所谓的高可用性。



###   Zookeeper 在 Kafka 中的作用知道吗？  

目前，Kafka使用ZooKeeper存放集群元数据、成员管理、Controller选举，以及其他一些管理类任务。

之后，等KIP-500提案完成后，Kafka将完全不再依赖于ZooKeeper。 

- “存放元数据”是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他“人” 都要与它保持对齐。
- “成员管理” 是指 Broker 节点的注册、注销以及属性变更，等等。
- “Controller 选举” 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置等。

KIP-500 思想，是使用社区自研的基于Raft的共识算法，替代ZooKeeper，实现Controller自选举



### 解释领导者和追随者的概念。

在Kafka的每个分区中，都有一个服务器充当领导者，0到多个服务器充当追随者的角色。

### 描述下Kafka中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别

Kafka副本当前分为领导者副本和追随者副本。只有Leader副本才能对外提供读写服务，响应Clients端的请求。Follower副本只是采用拉（PULL）的方式，被动地同步Leader副本中的数据，并且在Leader副本所在的Broker宕机后，随时准备应聘Leader副本。

加分点：

强调Follower副本也能对外提供读服务。自Kafka 2.4版本开始，社区通过引入新的Broker端参数，允许Follower副本有限度地提供读服务。

强调Leader和Follower的消息序列在实际场景中不一致。通常情况下，很多因素可能造成Leader和Follower之间的不同步，比如程序问题，网络问题，broker问题等，短暂的不同步我们可以关注（秒级别），但长时间的不同步可能就需要深入排查了，因为一旦Leader所在节点异常，可能直接影响可用性。

注意：之前确保一致性的主要手段是高水位机制（HW），但高水位值无法保证Leader连续变更场景下的数据一致性，因此，社区引入了Leader Epoch机制，来修复高水位值的弊端。

### kafka中的高水位机制

在 Kafka 中，高水位的作用主要有 2 个。

- 定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。
- 帮助 Kafka 完成副本同步。

高水位在界定 Kafka 消息对外可见性以及实现副本机制等方面起到了非常重要的作用，但其设计上的缺陷给 Kafka 留下了很多数据丢失或数据不一致的潜在风险。

为此，社区引入了 Leader Epoch 机制，尝试规避掉这类风险。

Leader Epoch，我们大致可以认为是Leader版本。它由两部分数据组成：

- 1）Epoch,一个单调增加的版本号。每当副本领导权发生变更时，都会增加该 版本号。
- 2）起始位移Leader副本在该Epoch值上写入的首条消息的位移。

### HW作用？

HW作用：保证消费数据的一致性和副本数据的一致性

- Follower故障
  - Follower发生故障后会被临时踢出ISR（动态变化），待该follower恢复后，follower会读取本地的磁盘记录的上次的HW，并将该log文件高于HW的部分截取掉，从HW开始向leader进行同步，等该follower的LEO大于等于该Partition的hw，即follower追上leader后，就可以重新加入ISR（In-Sync Replicas 副本同步队列）
- Leader故障
  - Leader发生故障后，会从ISR（In-Sync Replicas 副本同步队列）中选出一个新的leader，为了保证多个副本之间的数据一致性，其余的follower会先==将各自的log文件高于hw的部分截掉==（新leader自己不会截掉），然后从新的leader同步数据

### 是什么确保了Kafka中服务器的负载平衡？

由于领导者的主要角色是执行分区的所有读写请求的任务，而追随者被动地复制领导者。因此，在领导者失败时，其中一个追随者接管了领导者的角色。基本上，整个过程可确保服务器的负载平衡。



### 副本和ISR扮演什么角色？

复制日志的节点列表就是副本。特别是对于特定的分区。但是，无论他们是否扮演领导者的角色，他们都是如此。
此外，ISR指的是同步副本。在定义ISR时，它是一组与领导者同步的消息副本。

### 为什么Kafka的复制至关重要？

由于复制，我们可以确保发布的消息不会丢失，并且可以在发生任何机器错误、程序错误或频繁的软件升级时使用。

### **分区再分配是做什么的？解决了什么问题？**

分区再分配主要是用来维护 kafka 集群的负载均衡

既然是分区再分配，那么 kafka 分区有什么问题呢？

**问题1**：当集群中的一个节点下线了

- 如果该节点的分区是单副本的,那么分区将会变得不可用
- 如果是多副本的，就会进行 leader 选举，在其他机器上选举出新的 leader

**kafka 并不会将这些失效的分区迁移到其他可用的 broker 上**，这样就会影响集群的负载均衡，甚至也会影响服务的可靠性和可用性

**问题2**：集群新增 broker 时，只有新的主题分区会分配在该 [broker](https://www.zhihu.com/search?q=broker&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2535501775}) 上，而老的主题分区不会分配在该 broker 上，就造成了**老节点和新节点之间的负载不均衡**。

为了解决该问题就出现了分区再分配，它可以在集群扩容，broker 失效的场景下进行分区迁移。

**分区再分配的原理就是通化控制器给分区新增新的副本，然后通过网络把旧的副本数据复制到新的副本上，在复制完成后，将旧副本清除**。 当然，为了不影响集群正常的性能，在此复制期间还会有一系列保证性能的操作，比如**[复制限流](https://www.zhihu.com/search?q=复制限流&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2535501775})**。

### 为什么 Kafka不支持读写分离？

在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从而实现的是一种主写主读的生产消费模型。

Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:

==数据一致性问题==。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。

==延时问题==。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历 网络→主节点内存→网络→从节点内存 这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比Redis 更加耗时，它需要经历 网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘 这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。



### 当消费者在消费过程突然宕机了，重新恢复后是从哪里消费，会有什么问题？

消费者会记录offset，故障恢复后从这里继续消费，这个offset记录在哪里？

- 记录在zk里面和本地，新版默认将offset保证在kafka的内置topic中，名称是 __consumer_offsets
  - 该Topic默认有50个Partition，每个Partition有3个副本，分区数量由参数offset.topic.num.partition配置
  - 通过groupId的哈希值和该参数取模的方式来确定某个消费者组已消费的offset保存到__consumer_offsets主题的哪个分区中
  - 由 消费者组名+主题+分区，确定唯一的offset的key，从而获取对应的值
  - 三元组：**group.id+topic+分区号**，而 value 就是 offset 的值

## 参考

https://blog.csdn.net/wanghaiping1993/article/details/125346010

https://blog.csdn.net/wuhuagu_wuhuaguo/article/details/104716221

https://www.lixueduan.com/posts/kafka/12-hw-leader-epoch/

https://juejin.cn/post/6863264864140935175

kafka的顺序读写到底是什么？ - JavaPub的回答 - 知乎 https://www.zhihu.com/question/309414875/answer/2535501775

https://blog.csdn.net/wanghaiping1993/article/details/125346010

https://blog.csdn.net/tototuzuoquan/article/details/116573246